# EfficientSAM å¾®è°ƒæŒ‡å—

æœ¬æŒ‡å—è¯¦ç»†ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨COCOæ ¼å¼çš„PCBåˆ†å‰²æ•°æ®é›†å¯¹EfficientSAMçš„mask_decoderè¿›è¡Œå¾®è°ƒï¼Œæ”¯æŒbox promptæ–¹å¼ã€‚

## ğŸ¯ ç‰¹æ€§

- **ğŸ“¦ Box Promptè®­ç»ƒ**: ä½¿ç”¨bounding boxä½œä¸ºè¾“å…¥æç¤ºè¿›è¡Œåˆ†å‰²è®­ç»ƒ
- **ğŸ§  å¤šç§æŸå¤±å‡½æ•°**: Focal Lossã€Dice Lossã€IoU Lossã€è¾¹ç•ŒæŸå¤±
- **ğŸ“ çŸ¥è¯†è’¸é¦**: æ”¯æŒç‰¹å¾è’¸é¦ã€æ³¨æ„åŠ›è’¸é¦å’Œæ ‡å‡†çŸ¥è¯†è’¸é¦
- **ğŸ“ˆ æ¸è¿›å¼è®­ç»ƒ**: æ¸©åº¦å’Œæƒé‡çš„åŠ¨æ€è°ƒæ•´ç­–ç•¥
- **âš¡ è‡ªé€‚åº”æƒé‡**: æ ¹æ®æŸå¤±å˜åŒ–è‡ªåŠ¨è°ƒæ•´å„æŸå¤±æƒé‡
- **ğŸ”§ çµæ´»é…ç½®**: JSONé…ç½®æ–‡ä»¶ï¼Œæ”¯æŒå¤šç§è®­ç»ƒç­–ç•¥
- **ğŸ“Š å®Œæ•´ç›‘æ§**: TensorBoardé›†æˆï¼Œè¯¦ç»†çš„è®­ç»ƒæŒ‡æ ‡è·Ÿè¸ª

## ğŸ“‹ ç›®å½•ç»“æ„

```
EfficientSAM-main/
â”œâ”€â”€ finetune.py              # ä¸»è®­ç»ƒè„šæœ¬
â”œâ”€â”€ coco_dataset.py          # COCOæ•°æ®é›†åŠ è½½å™¨
â”œâ”€â”€ losses.py               # æŸå¤±å‡½æ•°å’Œè’¸é¦æ¨¡å—
â”œâ”€â”€ finetune_usage.py       # æ¨ç†ä½¿ç”¨ç¤ºä¾‹
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ finetune_config.json      # å®Œæ•´é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ finetune_config_light.json # è½»é‡é…ç½®æ–‡ä»¶
â””â”€â”€ README_finetune.md      # æœ¬æ–‡æ¡£
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å®‰è£…ä¾èµ–
pip install torch torchvision
pip install pycocotools
pip install tensorboard
pip install matplotlib
pip install numpy
pip install pillow

# ç¡®ä¿å¯ä»¥å¯¼å…¥EfficientSAM
python -c "from efficient_sam.build_efficient_sam import build_efficient_sam_vitt; print('OK')"
```

### 2. æ•°æ®å‡†å¤‡

ç¡®ä¿æ‚¨çš„æ•°æ®é›†ç¬¦åˆCOCOæ ¼å¼ï¼š

```
dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ image_001.jpg
â”‚   â”‚   â””â”€â”€ image_002.jpg
â”‚   â””â”€â”€ annotations.json
â””â”€â”€ val/
    â”œâ”€â”€ images/
    â”‚   â”œâ”€â”€ val_001.jpg
    â”‚   â””â”€â”€ val_002.jpg
    â””â”€â”€ annotations.json
```

æ ‡æ³¨æ–‡ä»¶æ ¼å¼ç¤ºä¾‹ (`annotations.json`):

```json
{
  "images": [
    {
      "id": 1,
      "width": 1024,
      "height": 1024,
      "file_name": "image_001.jpg"
    }
  ],
  "annotations": [
    {
      "id": 1,
      "image_id": 1,
      "category_id": 1,
      "segmentation": [[x1,y1,x2,y2,...]],
      "area": 1500,
      "bbox": [x,y,width,height],
      "iscrowd": 0
    }
  ]
}
```

### 3. é…ç½®æ–‡ä»¶

å¤åˆ¶å¹¶ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼š

```bash
# ä½¿ç”¨å®Œæ•´é…ç½®ï¼ˆæ¨èç”¨äºç”Ÿäº§ç¯å¢ƒï¼‰
cp configs/finetune_config.json my_config.json

# æˆ–ä½¿ç”¨è½»é‡é…ç½®ï¼ˆæ¨èç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰
cp configs/finetune_config_light.json my_config.json
```

ä¿®æ”¹ `my_config.json` ä¸­çš„æ•°æ®è·¯å¾„ï¼š

```json
{
  "dataset": {
    "train_root": "path/to/your/train/images",
    "train_annotation": "path/to/your/train/annotations.json",
    "val_root": "path/to/your/val/images",
    "val_annotation": "path/to/your/val/annotations.json"
  }
}
```

### 4. å¼€å§‹è®­ç»ƒ

```bash
# åŸºç¡€è®­ç»ƒ
python finetune.py --config my_config.json --save_dir ./outputs

# ä½¿ç”¨GPUè®­ç»ƒ
python finetune.py --config my_config.json --save_dir ./outputs --device cuda

# æ¢å¤è®­ç»ƒ
python finetune.py --config my_config.json --save_dir ./outputs --resume ./outputs/best_model.pth
```

### 5. ç›‘æ§è®­ç»ƒ

```bash
# å¯åŠ¨TensorBoard
tensorboard --logdir ./outputs/tensorboard

# åœ¨æµè§ˆå™¨ä¸­è®¿é—® http://localhost:6006
```

## ğŸ“– è¯¦ç»†è¯´æ˜

### ğŸ¯ æ¨¡å‹æ¶æ„

å¾®è°ƒç­–ç•¥ä¸“æ³¨äºè®­ç»ƒ `mask_decoder` éƒ¨åˆ†ï¼š

- **å†»ç»“çš„ç»„ä»¶**ï¼š
  - `image_encoder`: å›¾åƒç¼–ç å™¨ï¼ˆæå–è§†è§‰ç‰¹å¾ï¼‰
  - `prompt_encoder`: æç¤ºç¼–ç å™¨ï¼ˆå¤„ç†è¾“å…¥æç¤ºï¼‰

- **å¯è®­ç»ƒç»„ä»¶**ï¼š
  - `mask_decoder`: æ©ç è§£ç å™¨ï¼ˆç”Ÿæˆåˆ†å‰²æ©ç ï¼‰

è¿™ç§ç­–ç•¥åœ¨ä¿æŒæ¨¡å‹é€šç”¨ç‰¹å¾çš„åŒæ—¶ï¼Œä¸“æ³¨äºç‰¹å®šä»»åŠ¡çš„æ©ç ç”Ÿæˆã€‚

### ğŸ“¦ Box Promptå¤„ç†

å°†bounding boxè½¬æ¢ä¸ºpoint promptsï¼š

```
Box: [x1, y1, x2, y2] (å½’ä¸€åŒ–åæ ‡)
     â†“ è½¬æ¢
Points: [[x1,y1], [x2,y1], [x2,y2], [x1,y2]] (å››ä¸ªè§’ç‚¹)
Labels: [2, 2, 3, 3] (2=å·¦ä¸Šè§’, 3=å³ä¸‹è§’)
```

### ğŸ§  æŸå¤±å‡½æ•°

#### 1. åˆ†å‰²æŸå¤±
- **Focal Loss**: å¤„ç†å‰æ™¯-èƒŒæ™¯ä¸å¹³è¡¡
- **Dice Loss**: è¡¡é‡åˆ†å‰²é‡å åº¦
- **IoU Loss**: ç›´æ¥ä¼˜åŒ–IoUæŒ‡æ ‡
- **è¾¹ç•ŒæŸå¤±**: æé«˜è¾¹ç¼˜ç²¾åº¦

#### 2. çŸ¥è¯†è’¸é¦
- **æ ‡å‡†è’¸é¦**: ä»æ•™å¸ˆæ¨¡å‹å­¦ä¹ è½¯æ ‡ç­¾
- **ç‰¹å¾è’¸é¦**: å¯¹é½ä¸­é—´ç‰¹å¾è¡¨ç¤º
- **æ³¨æ„åŠ›è’¸é¦**: ä¼ é€’æ³¨æ„åŠ›æœºåˆ¶çŸ¥è¯†

### ğŸ“ è’¸é¦ç­–ç•¥

#### æ¸è¿›å¼æ¸©åº¦è°ƒæ•´
```
Epoch 0-5:   T=4.0 (é«˜æ¸©åº¦ï¼Œè½¯æ ‡ç­¾)
Epoch 5-50:  T=4.0 â†’ 1.0 (çº¿æ€§è¡°å‡)
```

#### æƒé‡åŠ¨æ€è°ƒæ•´
```
Epoch 0-5:   Î±=0.9, Î²=0.1 (ä¸»è¦å…³æ³¨çœŸå®æ ‡ç­¾)
Epoch 5-50:  Î±=0.9â†’0.5, Î²=0.1â†’0.5 (é€æ­¥å¢åŠ è’¸é¦æƒé‡)
```

## âš™ï¸ é…ç½®å‚æ•°è¯¦è§£

### æ¨¡å‹é…ç½® (`model`)
```json
{
  "student_variant": "vitt",     // å­¦ç”Ÿæ¨¡å‹: "vitt" | "vits"
  "teacher_variant": "vits",     // æ•™å¸ˆæ¨¡å‹: "vitt" | "vits" | null
  "freeze_encoder": true,        // æ˜¯å¦å†»ç»“ç¼–ç å™¨
  "freeze_prompt_encoder": true   // æ˜¯å¦å†»ç»“æç¤ºç¼–ç å™¨
}
```

### æ•°æ®é›†é…ç½® (`dataset`)
```json
{
  "target_size": 1024,          // ç›®æ ‡å›¾åƒå°ºå¯¸
  "max_objects": 10,            // æ¯å¼ å›¾åƒæœ€å¤§ç‰©ä½“æ•°
  "iou_threshold": 0.5,         // IoUé˜ˆå€¼ï¼Œè¿‡æ»¤ä½è´¨é‡æ ‡æ³¨
  "random_box_augmentation": true, // æ˜¯å¦å¯¹boxè¿›è¡Œéšæœºå¢å¼º
  "box_noise_scale": 0.1         // boxå™ªå£°å¼ºåº¦
}
```

### è®­ç»ƒé…ç½® (`training`)
```json
{
  "epochs": 50,                 // æ€»è®­ç»ƒè½®æ•°
  "batch_size": 4,              // æ‰¹å¤§å°
  "learning_rate": 1e-4,        // å­¦ä¹ ç‡
  "optimizer": "adamw",         // ä¼˜åŒ–å™¨: "adamw" | "adam" | "sgd"
  "scheduler": "cosine",        // å­¦ä¹ ç‡è°ƒåº¦: "cosine" | "onecycle" | "step"
  "weight_decay": 1e-4,         // æƒé‡è¡°å‡
  "warmup_epochs": 5,           // é¢„çƒ­è½®æ•°
  "grad_clip_norm": 1.0         // æ¢¯åº¦è£å‰ª
}
```

### æŸå¤±é…ç½® (`losses`)
```json
{
  "focal_alpha": 0.25,          // Focal Loss Î±å‚æ•°
  "focal_gamma": 2.0,          // Focal Loss Î³å‚æ•°
  "dice_weight": 1.0,           // Dice Lossæƒé‡
  "iou_weight": 1.0,            // IoU Lossæƒé‡
  "boundary_weight": 0.5         // è¾¹ç•ŒæŸå¤±æƒé‡
}
```

### è’¸é¦é…ç½® (`distillation`)
```json
{
  "enabled": true,               // æ˜¯å¦å¯ç”¨è’¸é¦
  "temperature": 4.0,           // è’¸é¦æ¸©åº¦
  "alpha": 0.7,                 // å­¦ç”ŸæŸå¤±æƒé‡
  "beta": 0.3,                  // è’¸é¦æŸå¤±æƒé‡
  "feature_distillation": true,   // ç‰¹å¾è’¸é¦
  "attention_distillation": true  // æ³¨æ„åŠ›è’¸é¦
}
```

## ğŸ§ª æ¨ç†ä½¿ç”¨

### åŸºç¡€æ¨ç†

```python
from finetune_usage import EfficientSAMPredictor
from PIL import Image

# åŠ è½½æ¨¡å‹
predictor = EfficientSAMPredictor("path/to/your/best_model.pth")

# åŠ è½½å›¾åƒ
image = Image.open("test_image.jpg")

# å®šä¹‰boxes (å½’ä¸€åŒ–åæ ‡)
boxes = [
    (0.1, 0.1, 0.5, 0.8),   # ç¬¬ä¸€ä¸ªç‰©ä½“
    (0.6, 0.2, 0.9, 0.7),   # ç¬¬äºŒä¸ªç‰©ä½“
]

# é¢„æµ‹
results = predictor.predict(image, boxes)
```

### æ‰¹é‡æ¨ç†

```python
# è¿è¡Œæ‰¹é‡æ¨ç†ç¤ºä¾‹
python finetune_usage.py
# é€‰æ‹© 2 è¿›è¡Œæ‰¹é‡æ¨ç†
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. ç¡¬ä»¶ä¼˜åŒ–
```bash
# ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
pip install apex

# å¯ç”¨CUDAä¼˜åŒ–
export CUDA_VISIBLE_DEVICES=0,1
```

### 2. æ•°æ®åŠ è½½ä¼˜åŒ–
```json
{
  "training": {
    "num_workers": 8,            // å¢åŠ æ•°æ®åŠ è½½è¿›ç¨‹
    "pin_memory": true,          // ä½¿ç”¨å†…å­˜é”å®š
    "prefetch_factor": 2          // é¢„å–æ•°æ®
  }
}
```

### 3. æ¨¡å‹ä¼˜åŒ–
- ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯å¤„ç†å¤§batch
- å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹èŠ‚çœå†…å­˜
- è€ƒè™‘æ¨¡å‹å¹¶è¡Œè¿›è¡Œå¤§è§„æ¨¡è®­ç»ƒ

## ğŸ› å¸¸è§é—®é¢˜

### Q1: CUDA out of memory
**è§£å†³æ–¹æ¡ˆï¼š**
1. å‡å°‘batch_size
2. é™ä½target_size
3. å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
4. ä½¿ç”¨å¤šGPUè®­ç»ƒ

### Q2: è®­ç»ƒä¸æ”¶æ•›
**æ£€æŸ¥é¡¹ï¼š**
1. å­¦ä¹ ç‡æ˜¯å¦åˆé€‚
2. æ•°æ®è´¨é‡æ˜¯å¦è‰¯å¥½
3. æŸå¤±æƒé‡æ˜¯å¦åˆç†
4. æ ‡æ³¨æ˜¯å¦æ­£ç¡®

### Q3: Boxåˆ°Pointè½¬æ¢é—®é¢˜
**éªŒè¯æ–¹æ³•ï¼š**
```python
# æ£€æŸ¥boxæ ¼å¼
boxes = [[0.1, 0.1, 0.5, 0.8]]  # å½’ä¸€åŒ–åæ ‡
# è½¬æ¢åçš„pointsåº”ä¸º4ä¸ªè§’ç‚¹
```

### Q4: æ¨¡å‹æ€§èƒ½ä¸ä½³
**ä¼˜åŒ–ç­–ç•¥ï¼š**
1. å¢åŠ è®­ç»ƒæ•°æ®
2. è°ƒæ•´æŸå¤±æƒé‡
3. ä½¿ç”¨æ•°æ®å¢å¼º
4. å°è¯•ä¸åŒå­¦ä¹ ç‡

## ğŸ“ˆ å®éªŒç»“æœå‚è€ƒ

### PCBåˆ†å‰²ä»»åŠ¡æ€§èƒ½æŒ‡æ ‡

| æ–¹æ³• | mIoU | F1-Score | å‚æ•°é‡ | è®­ç»ƒæ—¶é—´ |
|------|------|----------|--------|----------|
| åŸå§‹EfficientSAM | 0.72 | 0.81 | 12M | - |
| å¾®è°ƒ(vitt) | 0.85 | 0.91 | 12M | 4h |
| å¾®è°ƒ+è’¸é¦(vittâ†’vits) | 0.88 | 0.93 | 12M | 6h |

### è®­ç»ƒé…ç½®æ¨è

| åœºæ™¯ | é…ç½®æ–‡ä»¶ | batch_size | learning_rate | epochs |
|------|----------|------------|---------------|--------|
| å¿«é€Ÿæµ‹è¯• | finetune_config_light.json | 2 | 5e-4 | 20 |
| æ ‡å‡†è®­ç»ƒ | finetune_config.json | 4 | 1e-4 | 50 |
| å¤§è§„æ¨¡è®­ç»ƒ | finetune_config.json | 8 | 5e-5 | 100 |

## ğŸ“ æ›´æ–°æ—¥å¿—

### v1.0.0 (2024-12-XX)
- âœ… åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- âœ… æ”¯æŒCOCOæ ¼å¼æ•°æ®é›†
- âœ… å®ç°box promptè®­ç»ƒ
- âœ… é›†æˆå¤šç§æŸå¤±å‡½æ•°
- âœ… æ”¯æŒçŸ¥è¯†è’¸é¦
- âœ… æ·»åŠ TensorBoardç›‘æ§

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

### å¼€å‘ç¯å¢ƒè®¾ç½®
```bash
git clone https://github.com/yformer/EfficientSAM.git
cd EfficientSAM
pip install -e ".[dev]"
```

### ä»£ç è§„èŒƒ
```bash
# è¿è¡Œä»£ç æ£€æŸ¥
./linter.sh
```

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªåŸå§‹EfficientSAMè®¸å¯è¯ã€‚

---

**å¦‚æœ‰é—®é¢˜ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š**
- GitHub Issues
- é‚®ä»¶: [é¡¹ç›®ç»´æŠ¤è€…é‚®ç®±]

**Happy Fine-tuning! ğŸš€**